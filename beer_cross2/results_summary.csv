domain,model,prompt,split,accuracy,precision,recall,f1
Beer,cas,llama-3.2-3b-instruct_latest_chain_of_thought,test,0.8351648351648352,0.3333333333333333,0.07142857142857142,0.11764705882352941
Beer,cas,llama-3.2-3b-instruct_latest_domain,test,0.9010989010989011,1.0,0.35714285714285715,0.5263157894736842
Beer,cas,llama-3.2-3b-instruct_latest_fewshot,test,0.9230769230769231,0.8888888888888888,0.5714285714285714,0.6956521739130435
Beer,cas,llama-3.2-3b-instruct_latest_lenient,test,0.9340659340659341,0.7857142857142857,0.7857142857142857,0.7857142857142857
Beer,cas,llama-3.2-3b-instruct_latest_strict,test,0.8571428571428571,1.0,0.07142857142857142,0.13333333333333333
Beer,cas,llama-3.2-3b-instruct_latest_zero,test,0.8461538461538461,0.0,0.0,0.0
Beer,llama2,13b_strict,test,,0.0,0.0,0.0
Beer,llama3.1,chain_of_thought,test,0.8131868131868132,0.3333333333333333,0.21428571428571427,0.2608695652173913
Beer,llama3.1,domain,test,0.43956043956043955,0.2153846153846154,1.0,0.35443037974683544
Beer,llama3.1,fewshot,test,0.945054945054945,0.8,0.8571428571428571,0.8275862068965517
Beer,llama3.1,lenient,test,0.7362637362637363,0.3684210526315789,1.0,0.5384615384615384
Beer,llama3.1,strict,test,0.967032967032967,0.9230769230769231,0.8571428571428571,0.8888888888888888
Beer,llama3.1,zero,test,0.945054945054945,0.8,0.8571428571428571,0.8275862068965517
